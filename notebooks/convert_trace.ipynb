{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import coremltools as ct\n",
    "import numpy as np\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model_path = \"/path/to/DeepLabV3Plus-mobileone_s3.pt\"\n",
    "\n",
    "traced_model = torch.jit.load(traced_model_path)\n",
    "\n",
    "traced_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_width = 800\n",
    "input_height = 800\n",
    "\n",
    "# {'input_space': 'RGB', 'input_range': [0, 1], 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}\n",
    "std = [0.229, 0.224, 0.225]\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "scale = 1 / (np.mean(std) * 255.0)\n",
    "bias = [\n",
    "    - mean[0] / std[0],\n",
    "    - mean[1] / std[1],\n",
    "    - mean[2] / std[2],\n",
    "]\n",
    "\n",
    "input_shape = (1, 3, input_height, input_width) # NCHW\n",
    "\n",
    "image_input = ct.ImageType(\n",
    "    name=\"input\",\n",
    "    shape=input_shape,\n",
    "    color_layout=ct.colorlayout.RGB,\n",
    "    scale=scale,\n",
    "    bias=bias\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmodel_neuralnetwork = ct.convert(\n",
    "    traced_model,\n",
    "    inputs=[image_input],\n",
    "    convert_to=\"neuralnetwork\"\n",
    "    # convert_to=\"mlprogram\",\n",
    "    # minimum_deployment_target=ct.target.iOS16,\n",
    "    # compute_precision=ct.precision.FLOAT16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set metadata\n",
    "mlmodel_neuralnetwork.short_description = 'Wall segmentation model'\n",
    "mlmodel_neuralnetwork.input_description['input'] = 'Input RGB image'\n",
    "\n",
    "output = mlmodel_neuralnetwork._spec.description.output[0]\n",
    "output.type.multiArrayType.shape.append(input_height)\n",
    "output.type.multiArrayType.shape.append(input_width)\n",
    "\n",
    "ct.utils.rename_feature(\n",
    "    mlmodel_neuralnetwork._spec, \n",
    "    mlmodel_neuralnetwork.get_spec().description.output[0].name, \n",
    "    \"output\", \n",
    "    rename_inputs=True\n",
    ")\n",
    "\n",
    "mlmodel_neuralnetwork.output_description['output'] = \"Wall segmentation map\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = f'DeepLabV3Plus-mobileone_s1.neuralnetwork.mlmodel'\n",
    "mlmodel_neuralnetwork.save(model_filename)\n",
    "print(f'MLModel saved to {model_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmodel_mlprogram = ct.convert(\n",
    "    traced_model,\n",
    "    inputs=[image_input],\n",
    "    convert_to=\"mlprogram\"\n",
    "    # minimum_deployment_target=ct.target.iOS16,\n",
    "    # compute_precision=ct.precision.FLOAT16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = mlmodel_mlprogram.get_spec()\n",
    "print(\"model type: {}\".format(spec.WhichOneof('Type')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set metadata\n",
    "mlmodel_mlprogram.short_description = 'Wall segmentation model'\n",
    "mlmodel_mlprogram.input_description['input'] = 'Input RGB image'\n",
    "\n",
    "# output = mlmodel_mlprogram._spec.description.output[0]\n",
    "# output.type.multiArrayType.shape.append(input_height)\n",
    "# output.type.multiArrayType.shape.append(input_width)\n",
    "\n",
    "# ct.utils.rename_feature(\n",
    "#     mlmodel_mlprogram._spec, \n",
    "#     mlmodel_mlprogram.get_spec().description.output[0].name, \n",
    "#     \"output\", \n",
    "#     rename_inputs=True\n",
    "# )\n",
    "\n",
    "# mlmodel_mlprogram.output_description['output'] = \"Wall segmentation map\"\n",
    "\n",
    "labels_json = {\"labels\": [\"background\", \"wall\"]}\n",
    "\n",
    "mlmodel_mlprogram.user_defined_metadata[\"com.apple.coreml.model.preview.type\"] = \"imageSegmenter\"\n",
    "mlmodel_mlprogram.user_defined_metadata['com.apple.coreml.model.preview.params'] = json.dumps(labels_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = f'DeepLabV3Plus-mobileone_s1.mlprogram.mlpackage'\n",
    "mlmodel_mlprogram.save(model_filename)\n",
    "print(f'MLModel saved to {model_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
