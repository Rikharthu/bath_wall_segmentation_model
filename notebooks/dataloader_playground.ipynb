{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-09T21:01:13.611897061Z",
     "start_time": "2023-05-09T21:01:13.611578032Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: validate that DataLoader with augmented dataset on each new iteration produces samples with different augmentations (doesn't cache)\n",
    "#   Add print statement to Dataset augmentation part\n",
    "#   Start training model with limited dataset length (e.g.,) 10 images\n",
    "#   Ensure that debug print message is always printed on new epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikit-learn version 1.2.2 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")  # Try \"high\" as well\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "import mlflow\n",
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "\n",
    "import coremltools as ct\n",
    "\n",
    "from src.dataset import SimpleWallADE20KDataset\n",
    "from src.model import WallModel\n",
    "from src import config\n",
    "from src.transform import get_preprocessing_transform, get_train_augmentations, get_val_augmentations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T21:01:15.992348215Z",
     "start_time": "2023-05-09T21:01:13.611721330Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardsku/miniconda3/envs/ml/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1149: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "/home/ricardsku/miniconda3/envs/ml/lib/python3.10/site-packages/albumentations/augmentations/transforms.py:1175: FutureWarning: RandomContrast has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 8\n",
      "Validation size: 8\n",
      "Number of CPUs: 20\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = 8\n",
    "VAL_SIZE = 8\n",
    "\n",
    "# TODO: add option to not enforce specific image size, just pad to a multiple of 32,\n",
    "#   as it was done for image segmentation sample\n",
    "#   But first check if CoreML supports dynamic input size\n",
    "train_augmentations = get_train_augmentations()\n",
    "train_dataset = SimpleWallADE20KDataset(\n",
    "    root=config.DATA_ROOT,\n",
    "    mode='train',\n",
    "    length=TRAIN_SIZE,\n",
    "    augmentation_fn=train_augmentations,\n",
    "    preprocessing_fn=get_preprocessing_transform(config.ENCODER)\n",
    ")\n",
    "\n",
    "val_augmentations = get_val_augmentations()\n",
    "val_dataset = SimpleWallADE20KDataset(\n",
    "    root=config.DATA_ROOT,\n",
    "    mode='val',\n",
    "    length=TRAIN_SIZE,\n",
    "    augmentation_fn=val_augmentations,\n",
    "    preprocessing_fn=get_preprocessing_transform(config.ENCODER)\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Validation size: {len(val_dataset)}\")\n",
    "\n",
    "n_cpu = os.cpu_count()\n",
    "print(f'Number of CPUs: {n_cpu}')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=False, num_workers=n_cpu)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=n_cpu)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T21:02:49.315814506Z",
     "start_time": "2023-05-09T21:02:28.882904380Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "wall_model = WallModel(\n",
    "    architecture=config.ARCHITECTURE,\n",
    "    encoder_name=config.ENCODER,\n",
    "    in_channels=3,\n",
    "    out_classes=1,\n",
    "    learning_rate=config.LEARNING_RATE,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T21:02:49.382783579Z",
     "start_time": "2023-05-09T21:02:49.315519318Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type          | Params\n",
      "------------------------------------------\n",
      "0 | model   | DeepLabV3Plus | 11.3 M\n",
      "1 | loss_fn | DiceLoss      | 0     \n",
      "------------------------------------------\n",
      "11.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.3 M    Total params\n",
      "45.140    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting sample 2\n",
      "Augmenting sample 4\n",
      "Augmenting sample 5\n",
      "Augmenting sample 0\n",
      "Augmenting sample 3\n",
      "Augmenting sample 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardsku/miniconda3/envs/ml/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de3a363ad82f49799bb6185dcb85e335"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting sample 6\n",
      "Augmenting sample 2\n",
      "Augmenting sample 0\n",
      "Augmenting sample 7\n",
      "Augmenting sample 4\n",
      "Augmenting sample 1\n",
      "Augmenting sample 5\n",
      "Augmenting sample 3\n",
      "Augmenting sample 6\n",
      "Augmenting sample 2\n",
      "Augmenting sample 4\n",
      "Augmenting sample 0\n",
      "Augmenting sample 5\n",
      "Augmenting sample 3\n",
      "Augmenting sample 7\n",
      "Augmenting sample 1\n",
      "Augmenting sample 2Augmenting sample 6\n",
      "\n",
      "Augmenting sample 4\n",
      "Augmenting sample 0\n",
      "Augmenting sample 3\n",
      "Augmenting sample 5\n",
      "Augmenting sample 7\n",
      "Augmenting sample 1\n",
      "Augmenting sample 6\n",
      "Augmenting sample 2\n",
      "Augmenting sample 4\n",
      "Augmenting sample 7\n",
      "Augmenting sample 5Augmenting sample 0\n",
      "\n",
      "Augmenting sample 1Augmenting sample 3\n",
      "\n",
      "Augmenting sample 6\n",
      "Augmenting sample 2\n",
      "Augmenting sample 0\n",
      "Augmenting sample 4\n",
      "Augmenting sample 1\n",
      "Augmenting sample 5\n",
      "Augmenting sample 7\n",
      "Augmenting sample 3\n",
      "Augmenting sample 6Augmenting sample 2\n",
      "\n",
      "Augmenting sample 0\n",
      "Augmenting sample 4\n",
      "Augmenting sample 5\n",
      "Augmenting sample 1\n",
      "Augmenting sample 3\n",
      "Augmenting sample 7\n",
      "Augmenting sample 6\n",
      "Augmenting sample 2\n",
      "Augmenting sample 4\n",
      "Augmenting sample 0\n",
      "Augmenting sample 5\n",
      "Augmenting sample 3\n",
      "Augmenting sample 1\n",
      "Augmenting sample 7\n",
      "Augmenting sample 6\n",
      "Augmenting sample 2\n",
      "Augmenting sample 0\n",
      "Augmenting sample 7\n",
      "Augmenting sample 3\n",
      "Augmenting sample 4\n",
      "Augmenting sample 5\n",
      "Augmenting sample 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=8` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    devices=1,\n",
    "    max_epochs=8,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    wall_model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    #val_dataloaders=val_dataloader\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T21:03:00.434381149Z",
     "start_time": "2023-05-09T21:02:49.384496269Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
